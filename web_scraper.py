import requests
from bs4 import BeautifulSoup
import csv

def scrape_website(url):
    """Scrapes a website and extracts titles, links, and descriptions."""
    try:
        # Send HTTP request
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Raise an error for bad status codes
        
        # Parse HTML content
        soup = BeautifulSoup(response.text, "html.parser")
        
        # Extracting all articles (Modify based on website structure)
        articles = soup.find_all("article")  # Change this for other websites

        scraped_data = []
        for article in articles:
            title = article.find("h2").text.strip() if article.find("h2") else "No Title"
            link = article.find("a")["href"] if article.find("a") else "No Link"
            description = article.find("p").text.strip() if article.find("p") else "No Description"
            scraped_data.append([title, link, description])

        return scraped_data

    except requests.exceptions.RequestException as e:
        print(f"âŒ Error fetching data: {e}")
        return []

def save_to_csv(data, filename="scraped_data.csv"):
    """Saves extracted data to a CSV file."""
    try:
        with open(filename, "w", newline="", encoding="utf-8") as file:
            writer = csv.writer(file)
            writer.writerow(["Title", "Link", "Description"])  # Column headers
            writer.writerows(data)
        print(f"âœ… Data saved to {filename}")
    except Exception as e:
        print(f"âŒ Error saving CSV: {e}")

def main():
    """Main function to initiate web scraping."""
    url = input("ğŸŒ Enter website URL to scrape: ").strip()

    print("\nğŸ” Scraping data, please wait...\n")
    scraped_data = scrape_website(url)

    if scraped_data:
        for item in scraped_data:
            print(f"ğŸ“Œ Title: {item[0]}")
            print(f"ğŸ”— Link: {item[1]}")
            print(f"ğŸ“„ Description: {item[2]}\n")
        
        save_to_csv(scraped_data)
    else:
        print("âš ï¸ No data extracted. Try a different website.")

if __name__ == "__main__":
    main()
